# -*- coding: utf-8 -*-
"""Test_tech.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Iklza28nXpN_rx3CuQ7Q2a8tZirQJfzc
"""

import os
os.mkdir('Test_tech')

git init
git add
git commit -m "Initial commit"
import requests
import pandas as pd
import duckdb
import subprocess

# Étape 1 : Télécharger les données de l'API Ameli (pathologies Cancer, Île-de-France)
params = {
    'q': 'patho_niv1:Cancers ',
    'rows': 100,
    'dataset': 'effectifs'
}
url = "https://data.ameli.fr/api/records/1.0/search/"
response = requests.get(url, params=params)
data = response.json()

# Contrôle de la récupération effective des données
if 'records' not in data or len(data['records']) == 0:
    raise ValueError("Aucune donnée récupérée de l'API avec votre requête.")

records = [record['fields'] for record in data['records']]
df = pd.DataFrame(records)

if df.empty or df.shape[1] == 0:
    raise ValueError("Le DataFrame est vide ou sans colonnes, vérifiez la requête API.")

# Étape 1 bis : Enregistrer les données récupérées et faire un commit git
df.to_csv("recup_cancers_idf.csv", index=False)
subprocess.run(['git', 'add', 'recup_cancers_idf.csv'])
subprocess.run(['git', 'commit', '-m', "Données API Ameli (Cancers Île-de-France) récupérées"])

# Étape 2 : Créer la base DuckDB, importer les données dans la table cancers
con = duckdb.connect('cancers_idf.duckdb')
con.execute("CREATE TABLE IF NOT EXISTS cancers AS SELECT * FROM df")

# Étape 2 bis : Faire un commit après création et peuplement de la base
subprocess.run(['git', 'add', 'cancers_idf.duckdb'])
subprocess.run(['git', 'commit', '-m', "Base DuckDB créée et peuplée avec données cancers IDF"])

# Étape 3 : Générer un rapport HTML à partir de la base DuckDB
rapport = con.execute("SELECT pathologie, sexe, classe_age, nombre_patients, annee FROM cancers LIMIT 20").df()
html_content = rapport.to_html(index=False)

with open('rapport_cancers.html', 'w', encoding='utf-8') as f:
    f.write("<h2>Rapport : Exemples de cancers en Île-de-France</h2>")
    f.write(html_content)

# Étape 3 bis : Commit du rapport HTML généré
subprocess.run(['git', 'add', 'rapport_cancers.html'])
subprocess.run(['git', 'commit', '-m', "Rapport HTML généré à partir de la base DuckDB"])

print("Rapport HTML créé et tout l’historique de chaque étape suivi par git !")



import os
os.mkdir('Test_tech')

#git init
#git add
#git commit -m "Initial commit"

import requests
import pandas as pd
import duckdb
import subprocess

# Étape 1 : Télécharger les données de l'API Ameli (pathologies Cancer, Île-de-France)
params = {
    'q': 'patho_niv1:Cancers, region:11',
    'rows': 100,
    'dataset': 'effectifs'
}
url = "https://data.ameli.fr/api/records/1.0/search/"
response = requests.get(url, params=params)
data = response.json()

# Contrôle de la récupération effective des données
if 'records' not in data or len(data['records']) == 0:
    raise ValueError("Aucune donnée récupérée de l'API avec votre requête.")

records = [record['fields'] for record in data['records']]
df = pd.DataFrame(records)

if df.empty or df.shape[1] == 0:
    raise ValueError("Le DataFrame est vide ou sans colonnes, vérifiez la requête API.")

# Étape 1 bis : Enregistrer les données récupérées et faire un commit git
df.to_csv("recup_cancers_idf.csv", index=False)
subprocess.run(['git', 'add', 'recup_cancers_idf.csv'])
subprocess.run(['git', 'commit', '-m', "Données API Ameli (Cancers Île-de-France) récupérées"])

# Étape 2 : Créer la base DuckDB, importer les données dans la table cancers
con = duckdb.connect('cancers_idf.duckdb')
con.execute("CREATE TABLE IF NOT EXISTS cancers AS SELECT * FROM df")

# Étape 2 bis : Faire un commit après création et peuplement de la base
subprocess.run(['git', 'add', 'cancers_idf.duckdb'])
subprocess.run(['git', 'commit', '-m', "Base DuckDB créée et peuplée avec données cancers IDF"])

# Étape 3 : Générer un rapport HTML à partir de la base DuckDB
rapport = con.execute("SELECT * FROM cancers LIMIT 100").df()
html_content = rapport.to_html(index=False)

with open('rapport_cancers.html', 'w', encoding='utf-8') as f:
    f.write("<h2>Rapport : Exemples de cancers en Île-de-France</h2>")
    f.write(html_content)

# Étape 3 bis : Commit du rapport HTML généré
subprocess.run(['git', 'add', 'rapport_cancers.html'])
subprocess.run(['git', 'commit', '-m', "Rapport HTML généré à partir de la base DuckDB"])

print("Rapport HTML créé et tout l’historique de chaque étape suivi par git !")

import requests
import pandas as pd
import duckdb
from google.colab import files

# --- Étape 1 : Extraction des données de l'API Ameli ---
params = {
    'q': 'patho_niv1:Cancers AND region:11',
    'rows': 100,
    'dataset': 'effectifs'
}
url = "https://data.ameli.fr/api/records/1.0/search/"
response = requests.get(url, params=params)
data = response.json()

if 'records' not in data or len(data['records']) == 0:
    raise ValueError("Aucune donnée récupérée pour votre requête.")

records = [record['fields'] for record in data['records']]
df = pd.DataFrame(records)

if df.empty or df.shape[1] == 0:
    raise ValueError("Le DataFrame est vide : vérifiez la requête API.")

# --- Étape 2 : Sauvegarde et téléchargement du CSV ---
csv_name = "recup_cancers_idf.csv"
df.to_csv(csv_name, index=False)
files.download(csv_name)        # Permet de télécharger le fichier sur votre PC

# --- Étape 3 : Création base DuckDB et sauvegarde ---
db_name = "cancers_idf.duckdb"
con = duckdb.connect(db_name)
con.execute("CREATE TABLE IF NOT EXISTS cancers AS SELECT * FROM df")
con.close()
files.download(db_name)         # Permet de télécharger la base DuckDB

# --- Étape 4 : Génération du rapport HTML ---
con = duckdb.connect(db_name, read_only=True)
rapport = con.execute("SELECT * FROM cancers LIMIT 100").df()
html_name = "rapport_cancers.html"
with open(html_name, "w", encoding="utf-8") as f:
    f.write("<h2>Rapport : Exemples de cancers en Île-de-France</h2>")
    f.write(rapport.to_html(index=False))
con.close()
files.download(html_name)       # Permet de télécharger le rapport HTML

print("Tous les fichiers créés. Téléchargez-les depuis Colab puis uploadez-les sur votre dépôt GitHub.")